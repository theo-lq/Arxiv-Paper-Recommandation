{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fine-Tuning ModernBert for Arxiv Paper Recommandation\n",
        "\n",
        "Based on a manually annotated dataset, we want to build a classifier to decide whether or not a paper will be interesting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZsjETMkScOEC",
        "outputId": "f169b34b-21a6-4197-911b-f5f1a82a539f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper_id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>categories</th>\n",
              "      <th>submission_date</th>\n",
              "      <th>interest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2411.18620</td>\n",
              "      <td>Cross-modal Information Flow in Multimodal Lar...</td>\n",
              "      <td>The recent advancements in auto-regressive m...</td>\n",
              "      <td>cs.AI, cs.CL, cs.CV</td>\n",
              "      <td>2024-11-27 18:59:26+00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2411.18616</td>\n",
              "      <td>Diffusion Self-Distillation for Zero-Shot Cust...</td>\n",
              "      <td>Text-to-image diffusion models produce impre...</td>\n",
              "      <td>cs.CV, cs.AI, cs.GR, cs.LG</td>\n",
              "      <td>2024-11-27 18:58:52+00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2411.18615</td>\n",
              "      <td>Proactive Gradient Conflict Mitigation in Mult...</td>\n",
              "      <td>Advancing towards generalist agents necessit...</td>\n",
              "      <td>cs.LG, cs.AI, cs.CV</td>\n",
              "      <td>2024-11-27 18:58:22+00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2411.18612</td>\n",
              "      <td>Robust Offline Reinforcement Learning with Lin...</td>\n",
              "      <td>The Distributionally Robust Markov Decision ...</td>\n",
              "      <td>cs.LG, cs.AI, cs.RO, stat.ML</td>\n",
              "      <td>2024-11-27 18:57:03+00:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2411.18583</td>\n",
              "      <td>Automated Literature Review Using NLP Techniqu...</td>\n",
              "      <td>This research presents and compares multiple...</td>\n",
              "      <td>cs.CL, cs.AI, cs.IR, cs.LG</td>\n",
              "      <td>2024-11-27 18:27:07+00:00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     paper_id                                              title  \\\n",
              "0  2411.18620  Cross-modal Information Flow in Multimodal Lar...   \n",
              "1  2411.18616  Diffusion Self-Distillation for Zero-Shot Cust...   \n",
              "2  2411.18615  Proactive Gradient Conflict Mitigation in Mult...   \n",
              "3  2411.18612  Robust Offline Reinforcement Learning with Lin...   \n",
              "4  2411.18583  Automated Literature Review Using NLP Techniqu...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0    The recent advancements in auto-regressive m...   \n",
              "1    Text-to-image diffusion models produce impre...   \n",
              "2    Advancing towards generalist agents necessit...   \n",
              "3    The Distributionally Robust Markov Decision ...   \n",
              "4    This research presents and compares multiple...   \n",
              "\n",
              "                     categories           submission_date  interest  \n",
              "0           cs.AI, cs.CL, cs.CV 2024-11-27 18:59:26+00:00         0  \n",
              "1    cs.CV, cs.AI, cs.GR, cs.LG 2024-11-27 18:58:52+00:00         0  \n",
              "2           cs.LG, cs.AI, cs.CV 2024-11-27 18:58:22+00:00         0  \n",
              "3  cs.LG, cs.AI, cs.RO, stat.ML 2024-11-27 18:57:03+00:00         0  \n",
              "4    cs.CL, cs.AI, cs.IR, cs.LG 2024-11-27 18:27:07+00:00         1  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"Dataset.csv\")\n",
        "df['submission_date'] = pd.to_datetime(df['submission_date'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The classification is imbalanced :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgso0Lb-1uwl",
        "outputId": "e8fc8b4b-5454-4fa3-e5ed-827182c627af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proportion of positive class : 7.03%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Proportion of positive class : {100 * df[\"interest\"].mean():.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This means that we will have to take the imbalanced into account for the training.\n",
        "\n",
        "## Preparation\n",
        "\n",
        "For the classification the abstract of the paper will be the only feature, and we will keep 75% of the dataset for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "3ec5VOE7cdoB"
      },
      "outputs": [],
      "source": [
        "df = df.sort_values('submission_date')\n",
        "train_size = 0.75\n",
        "max_train_index = int(train_size * len(df))\n",
        "\n",
        "abstracts = df['abstract'].tolist()\n",
        "labels = df['interest'].tolist()\n",
        "\n",
        "train_texts, val_texts = abstracts[:max_train_index], abstracts[max_train_index:]\n",
        "train_labels, val_labels = labels[:max_train_index], labels[max_train_index:]\n",
        "\n",
        "train_dataset = Dataset.from_dict({'text': train_texts, 'label': train_labels})\n",
        "validation_dataset = Dataset.from_dict({'text': val_texts, 'label': val_labels})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check the imbalance in both datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 7.34%\n",
            "Validation: 6.11%\n"
          ]
        }
      ],
      "source": [
        "for (vector, name) in zip([train_labels, val_labels], [\"Train\", \"Validation\"]):\n",
        "    ratio = 100 * np.array(vector).mean()\n",
        "    print(f\"{name}: {ratio:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this notebook we'll fine-tune the ModernBERT-base model. One can change the `model_name` variable to switch from one model to another on HuggingFace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "d2ad375f55ee481c84ecaabed781ff8b",
            "9ff28c2df88b43ce89a8b04cd25bf375",
            "53129bf630444613a826499f569878c7",
            "acc1cf89f3ee4819b47b4c150409ce72",
            "4918f5f6401542ef958a0e2b8c5efd56",
            "9a70ee62f1ab4c40b2ae4b2767371833",
            "a8bbaa6ec84346f8a1648fa3d2571a69",
            "255de73d638c4a569989b106e15909b0",
            "1b9f195298e44e69ad99cb5d8654c1d3",
            "5d9054c5548c468697b4d4ef5653dee6",
            "a7b76a19f26b4a9fa38746122f70ad74",
            "dc9a2799168044cab69ef1decb9ce884",
            "e8844db6c9f24128885a0dfdb2bf19f4",
            "fc2140684a614e33a90853939b5a1daf",
            "466b835b30c64763b12de3806a4a8cdc",
            "f34edfcc3b044be1ba150b81090cdc8a",
            "0af56e2ea96a4aa28816954ed32f914c",
            "f4e39571c73d4f0ebf4b84de11b049fc",
            "04e0877932a14b1882294d76add72f5e",
            "3b63d9f2298a4e9da551bacaee024fc5",
            "15af3efaca7f462aa4aa9ce7e5c77178",
            "2f5eb807da904d629262cfcd8722dbd9",
            "041c3da434d94dd1bdfbd46bdcf519eb",
            "0f2a7bc17f604670be12bc567ddb2751",
            "7bb3d0c1bce44fae80f006f5709b7b69",
            "83630888910b456bafd9a67ac32fbcb1",
            "498544775cac4691a8fae89d297c81d3",
            "21cb09527e224c059f061b906f7a841e",
            "6c61fe0fde114560b301b7048f6a7e10",
            "0c388cb9342b4fbdaa35eca93d34e348",
            "881705e1273e44e881f11d64804b9185",
            "f278e7bbbd954919bd1da4efcf0866b7",
            "9ba8e7f9fb0c437d827d41cd1ea21951",
            "468b3ec7c678471f99567ba40b66ab57",
            "65745083fa61487a91b5581ca092f232",
            "4282aa9a732548b194702e2b937b0390",
            "bd992956e47c41c68ccfd41b8fec0380",
            "8d42d82130ff464480020a95a7d8a926",
            "71a293384c114bb8b7d76874ecc9eea9",
            "386eebf905f74f3e9a9f1e6c0ef6688a",
            "5ff6916e84f44ec49d359ba252cbff67",
            "18b495ccac2e44e4abdaaf099a3b76a2",
            "d2c41c6f47f143578b9e269cec67f676",
            "9a614b73c5f94d1a872eb44fd916133e",
            "897858d0953140dea5ae718956869d73",
            "49c83f426436433a8c39364fc71966b8",
            "97637c83ed7e4b5a8a66d468b0dca527",
            "41102555060d4569a786cedcc785e9f6",
            "21d010d256c849f1936978013596bee1",
            "ff189e1e253d453b945224c54bd35846",
            "671682fc1c7243a3b97352a52308a5c0",
            "daacc56bef12466a91f8e8b63b8b9409",
            "834c4ec09c8b4c1e9795c892a52866b1",
            "f392df123c9a42f2bf3eb6f9c5cb0b72",
            "9e2f19394dd24077a52a05b07abb7c99"
          ]
        },
        "id": "U41yzLSdcx1G",
        "outputId": "9efda842-3013-476d-8a5f-18a76656e257"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"answerdotai/ModernBERT-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before training, we need to follow three steps :\n",
        "1. Tokenization : transform text to an array of tokens, each representing a sequence of character\n",
        "2. Define a custom trainer class that take into account the class imbalance\n",
        "3. Define a function that will measure performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "dcabbfd7d22b4db884b11ba35f4781c6",
            "6f6b5e7258e447f2aa9a8b8cfe56a721",
            "da1709a7d2c74b838c1316352b6d69e8",
            "731e6ad98f8142f9b56043ae75c69900",
            "ccd0a8a3c43a437dac8bee685d89561c",
            "bab6e96ccb144d36befda2d1c70bad93",
            "6208c326624a4ffc9d7b3f530eafba26",
            "4ad932ec8bde4de385ff9bad774ca647",
            "fd63392d24a641a495c8f17d31e90c4f",
            "ad2f1079caba468c8d8a6cceb14be6c5",
            "83563749f6fd45a88d9ad1b21a3e3dc6",
            "d234508479794483876701c041f7a195",
            "2a2fef74bd624b7c88aea6b56988ad4a",
            "2f3f9b4a39294e18b8b4d0d7cbc626a5",
            "72b8cb1f96a94b5a9d35a6c87e70b4ad",
            "1d9d1d33bef2416380048c954f8495fe",
            "ef64d246d81e4e91814932db4eba15fc",
            "e5ccca2a3fc94980b19b985e7e6cc8fb",
            "719cf28fc98c475d92591803e4e73f11",
            "d2fd9d3cf96c450bb4c4ce2e7316a8cd",
            "68647247bd8c4b499e67a75ec99c6b7a",
            "6f88e745264042f98bf2d6a17d453b28"
          ]
        },
        "id": "A95I6OIZuHJn",
        "outputId": "0ee88ed3-4e07-48cd-e946-f46a4cc556c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2943/2943 [00:00<00:00, 7017.25 examples/s]\n",
            "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 982/982 [00:00<00:00, 7357.25 examples/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128).to(device)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "validation_dataset = validation_dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The classic Trainer class from HuggingFace doesn't support natively the class imbalanced. Therefore we implement a modification of the CrossEntropyLoss and we make sure everything is avaible on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1RT5iFaMxAoN"
      },
      "outputs": [],
      "source": [
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).clone().detach().to(device)\n",
        "\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get('logits')\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since the classification is imbalanced, measuring the performance with accuracy is not rigourous. We will compute precision, recall and f1-score for the threshold that achieve the best f1-score. We will then track accuracy, precision, recall, f1 and the threshold used to compute all of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(p):\n",
        "    logits, y_true = p\n",
        "    y_proba = 1/(1+np.exp(-logits))[:, 1]\n",
        "\n",
        "    best_threshold = 0\n",
        "    best_f1 = 0\n",
        "    probabilities = set(y_proba)\n",
        "\n",
        "    for threshold in probabilities:\n",
        "        y_pred = (y_proba >= threshold).astype(int)\n",
        "        f1 = f1_score(y_true, y_pred)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "    y_pred = (y_proba >= best_threshold).astype(int)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
        "    answer = {\n",
        "        'threshold': best_threshold,\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We checked all the previous tasks, let's start the training.\n",
        "\n",
        "## Training\n",
        "\n",
        "We will use the [TrainingArguments](https://huggingface.co/docs/transformers/v4.48.2/en/main_classes/trainer#transformers.TrainingArguments) to feed the CustomTrainer previously defined. All the logs and weights will be saved into a specific folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "nCEcyXMgcaaA",
        "outputId": "f4b0fe80-823f-4147-805e-c2a8f5feee42"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/training_args.py:2243: UserWarning: `use_mps_device` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. `mps` device will be used by default if available similar to the way `cuda` device is used.Therefore, no action from user is required. \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='644' max='644' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [644/644 29:31, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Threshold</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.512460</td>\n",
              "      <td>0.339706</td>\n",
              "      <td>0.890020</td>\n",
              "      <td>0.419355</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.565217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.445514</td>\n",
              "      <td>0.348267</td>\n",
              "      <td>0.914460</td>\n",
              "      <td>0.493976</td>\n",
              "      <td>0.422680</td>\n",
              "      <td>0.594203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.462675</td>\n",
              "      <td>0.436915</td>\n",
              "      <td>0.919552</td>\n",
              "      <td>0.496815</td>\n",
              "      <td>0.443182</td>\n",
              "      <td>0.565217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.502517</td>\n",
              "      <td>0.310582</td>\n",
              "      <td>0.905295</td>\n",
              "      <td>0.486188</td>\n",
              "      <td>0.392857</td>\n",
              "      <td>0.637681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.718026</td>\n",
              "      <td>0.143553</td>\n",
              "      <td>0.907332</td>\n",
              "      <td>0.485876</td>\n",
              "      <td>0.398148</td>\n",
              "      <td>0.623188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.369300</td>\n",
              "      <td>0.714898</td>\n",
              "      <td>0.176245</td>\n",
              "      <td>0.912424</td>\n",
              "      <td>0.494118</td>\n",
              "      <td>0.415842</td>\n",
              "      <td>0.608696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.369300</td>\n",
              "      <td>0.712178</td>\n",
              "      <td>0.187776</td>\n",
              "      <td>0.915479</td>\n",
              "      <td>0.496970</td>\n",
              "      <td>0.427083</td>\n",
              "      <td>0.594203</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=644, training_loss=0.32439060685057075, metrics={'train_runtime': 1773.8054, 'train_samples_per_second': 11.614, 'train_steps_per_second': 0.363, 'total_flos': 1754988096443904.0, 'train_loss': 0.32439060685057075, 'epoch': 7.0})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=7,\n",
        "    weight_decay=0.05,\n",
        "    learning_rate=5e-6,\n",
        "    warmup_ratio=0.1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    report_to=[],\n",
        "    use_mps_device=True\n",
        ")\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_arguments,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With training finished, we can evaluate the best model on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.7121782302856445, 'eval_threshold': 0.18777596950531006, 'eval_accuracy': 0.9154786150712831, 'eval_f1': 0.49696969696969695, 'eval_precision': 0.4270833333333333, 'eval_recall': 0.5942028985507246, 'eval_runtime': 30.7812, 'eval_samples_per_second': 31.903, 'eval_steps_per_second': 2.014, 'epoch': 7.0}\n"
          ]
        }
      ],
      "source": [
        "evaluation = trainer.evaluate()\n",
        "print(evaluation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t8bWtfFzuP9"
      },
      "source": [
        "## Errors on validation\n",
        "\n",
        "We want to check manually the errors of the dataset to decide whether is it a prediction error or a labellisation error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3ZQm712ax5np",
        "outputId": "5238f91f-fc0e-4097-9946-8ebe72833455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proba=0.2457 and label=0\n",
            "  The metaphor studies community has developed numerous valuable labelled\n",
            "corpora in various languages over the years. Many of these resources are not\n",
            "only unknown to the NLP community, but are also often not easily shared among\n",
            "the researchers. Both in human sciences and in NLP, researchers could benefit\n",
            "from a centralised database of labelled resources, easily accessible and\n",
            "unified under an identical format. To facilitate this, we present\n",
            "MetaphorShare, a website to integrate metaphor datasets making them open and\n",
            "accessible. With this effort, our aim is to encourage researchers to share and\n",
            "upload more datasets in any language in order to facilitate metaphor studies\n",
            "and the development of future metaphor processing NLP systems. The website is\n",
            "accessible at www.metaphorshare.com.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2969 and label=0\n",
            "  Bitcoin has increased investment interests in people during the last decade.\n",
            "We have seen an increase in the number of posts on social media platforms about\n",
            "cryptocurrency, especially Bitcoin. This project focuses on analyzing user\n",
            "tweet data in combination with Bitcoin price data to see the relevance between\n",
            "price fluctuations and the conversation between millions of people on Twitter.\n",
            "This study also exploits this relationship between user tweets and bitcoin\n",
            "prices to predict the future bitcoin price. We are utilizing novel techniques\n",
            "and methods to analyze the data and make price predictions.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.4207 and label=0\n",
            "  When we speak, write or listen, we continuously make predictions based on our\n",
            "knowledge of a language's grammar. Remarkably, children acquire this\n",
            "grammatical knowledge within just a few years, enabling them to understand and\n",
            "generalise to novel constructions that have never been uttered before. Language\n",
            "models are powerful tools that create representations of language by\n",
            "incrementally predicting the next word in a sentence, and they have had a\n",
            "tremendous societal impact in recent years. The central research question of\n",
            "this thesis is whether these models possess a deep understanding of grammatical\n",
            "structure similar to that of humans. This question lies at the intersection of\n",
            "natural language processing, linguistics, and interpretability. To address it,\n",
            "we will develop novel interpretability techniques that enhance our\n",
            "understanding of the complex nature of large-scale language models. We approach\n",
            "our research question from three directions. First, we explore the presence of\n",
            "abstract linguistic information through structural priming, a key paradigm in\n",
            "psycholinguistics for uncovering grammatical structure in human language\n",
            "processing. Next, we examine various linguistic phenomena, such as adjective\n",
            "order and negative polarity items, and connect a model's comprehension of these\n",
            "phenomena to the data distribution on which it was trained. Finally, we\n",
            "introduce a controlled testbed for studying hierarchical structure in language\n",
            "models using various synthetic languages of increasing complexity and examine\n",
            "the role of feature interactions in modelling this structure. Our findings\n",
            "offer a detailed account of the grammatical knowledge embedded in language\n",
            "model representations and provide several directions for investigating\n",
            "fundamental linguistic questions using computational methods.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2599 and label=0\n",
            "  We analyze the convergence of Gauss-Newton dynamics for training neural\n",
            "networks with smooth activation functions. In the underparameterized regime,\n",
            "the Gauss-Newton gradient flow induces a Riemannian gradient flow on a\n",
            "low-dimensional, smooth, embedded submanifold of the Euclidean output space.\n",
            "Using tools from Riemannian optimization, we prove \\emph{last-iterate}\n",
            "convergence of the Riemannian gradient flow to the optimal in-class predictor\n",
            "at an \\emph{exponential rate} that is independent of the conditioning of the\n",
            "Gram matrix, \\emph{without} requiring explicit regularization. We further\n",
            "characterize the critical impacts of the neural network scaling factor and the\n",
            "initialization on the convergence behavior. In the overparameterized regime, we\n",
            "show that the Levenberg-Marquardt dynamics with an appropriately chosen damping\n",
            "factor yields robustness to ill-conditioned kernels, analogous to the\n",
            "underparameterized regime. These findings demonstrate the potential of\n",
            "Gauss-Newton methods for efficiently optimizing neural networks, particularly\n",
            "in ill-conditioned problems where kernel and Gram matrices have small singular\n",
            "values.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2426 and label=0\n",
            "  Causal Language Modeling (CLM) and Masked Language Modeling (MLM) are two\n",
            "mainstream learning paradigms based on Transformer networks, specifically the\n",
            "Decoder-only and Encoder-only architectures. The strengths of each paradigm in\n",
            "downstream tasks have shown a mix of advantages and disadvantages. In the past\n",
            "BabyLM Challenge 2023, although the MLM paradigm achieved the best average\n",
            "performance, the CLM paradigm demonstrated significantly faster convergence\n",
            "rates. For the BabyLM Challenge 2024, we propose a novel language modeling\n",
            "paradigm named $\\textbf{AntLM}$, which integrates both CLM and MLM to leverage\n",
            "the advantages of these two classic paradigms. We chose the strict-small track\n",
            "and conducted experiments on two foundation models: BabyLlama, representing\n",
            "CLM, and LTG-BERT, representing MLM. During the training process for specific\n",
            "foundation models, we alternate between applying CLM or MLM training objectives\n",
            "and causal or bidirectional attention masks. Experimental results show that\n",
            "combining the two pretraining objectives leverages their strengths, enhancing\n",
            "overall training performance. Under the same epochs, $AntLM_{BabyLlama}$\n",
            "improves Macro-average by 1%, and $AntLM_{LTG-BERT}$ achieves a 2.2% increase\n",
            "over the baselines.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.3342 and label=0\n",
            "  The exponential growth of online textual content across diverse domains has\n",
            "necessitated advanced methods for automated text classification. Large Language\n",
            "Models (LLMs) based on transformer architectures have shown significant success\n",
            "in this area, particularly in natural language processing (NLP) tasks. However,\n",
            "general-purpose LLMs often struggle with domain-specific content, such as\n",
            "scientific texts, due to unique challenges like specialized vocabulary and\n",
            "imbalanced data. In this study, we fine-tune four state-of-the-art LLMs BERT,\n",
            "SciBERT, BioBERT, and BlueBERT on three datasets derived from the WoS-46985\n",
            "dataset to evaluate their performance in scientific text classification. Our\n",
            "experiments reveal that domain-specific models, particularly SciBERT,\n",
            "consistently outperform general-purpose models in both abstract-based and\n",
            "keyword-based classification tasks. Additionally, we compare our achieved\n",
            "results with those reported in the literature for deep learning models, further\n",
            "highlighting the advantages of LLMs, especially when utilized in specific\n",
            "domains. The findings emphasize the importance of domain-specific adaptations\n",
            "for LLMs to enhance their effectiveness in specialized text classification\n",
            "tasks.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2218 and label=0\n",
            "  The lack of data transparency in Large Language Models (LLMs) has highlighted\n",
            "the importance of Membership Inference Attack (MIA), which differentiates\n",
            "trained (member) and untrained (non-member) data. Though it shows success in\n",
            "previous studies, recent research reported a near-random performance in\n",
            "different settings, highlighting a significant performance inconsistency. We\n",
            "assume that a single setting doesn't represent the distribution of the vast\n",
            "corpora, causing members and non-members with different distributions to be\n",
            "sampled and causing inconsistency. In this study, instead of a single setting,\n",
            "we statistically revisit MIA methods from various settings with thousands of\n",
            "experiments for each MIA method, along with study in text feature, embedding,\n",
            "threshold decision, and decoding dynamics of members and non-members. We found\n",
            "that (1) MIA performance improves with model size and varies with domains,\n",
            "while most methods do not statistically outperform baselines, (2) Though MIA\n",
            "performance is generally low, a notable amount of differentiable member and\n",
            "non-member outliers exists and vary across MIA methods, (3) Deciding a\n",
            "threshold to separate members and non-members is an overlooked challenge, (4)\n",
            "Text dissimilarity and long text benefit MIA performance, (5) Differentiable or\n",
            "not is reflected in the LLM embedding, (6) Member and non-members show\n",
            "different decoding dynamics.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.4625 and label=0\n",
            "  Artificial intelligence has, so far, largely automated routine tasks, but\n",
            "what does it mean for the future of work if Large Language Models (LLMs) show\n",
            "creativity comparable to humans? To measure the creativity of LLMs\n",
            "holistically, the current study uses 13 creative tasks spanning three domains.\n",
            "We benchmark the LLMs against individual humans, and also take a novel approach\n",
            "by comparing them to the collective creativity of groups of humans. We find\n",
            "that the best LLMs (Claude and GPT-4) rank in the 52nd percentile against\n",
            "humans, and overall LLMs excel in divergent thinking and problem solving but\n",
            "lag in creative writing. When questioned 10 times, an LLM's collective\n",
            "creativity is equivalent to 8-10 humans. When more responses are requested, two\n",
            "additional responses of LLMs equal one extra human. Ultimately, LLMs, when\n",
            "optimally applied, may compete with a small group of humans in the future of\n",
            "work.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2353 and label=0\n",
            "  This paper addresses non-Gaussian regression with neural networks via the use\n",
            "of the Tukey g-and-h distribution.The Tukey g-and-h transform is a flexible\n",
            "parametric transform with two parameters $g$ and $h$ which, when applied to a\n",
            "standard normal random variable, introduces both skewness and kurtosis,\n",
            "resulting in a distribution commonly called the Tukey g-and-h distribution.\n",
            "Specific values of $g$ and $h$ produce good approximations to other families of\n",
            "distributions, such as the Cauchy and student-t distributions. The flexibility\n",
            "of the Tukey g-and-h distribution has driven its popularity in the statistical\n",
            "community, in applied sciences and finance. In this work we consider the\n",
            "training of a neural network to predict the parameters of a Tukey g-and-h\n",
            "distribution in a regression framework via the minimization of the\n",
            "corresponding negative log-likelihood, despite the latter having no closed-form\n",
            "expression. We demonstrate the efficiency of our procedure in simulated\n",
            "examples and apply our method to a real-world dataset of global crop yield for\n",
            "several types of crops. Finally, we show how we can carry out a goodness-of-fit\n",
            "analysis between the predicted distributions and the test data. A Pytorch\n",
            "implementation is made available on Github and as a Pypi package.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2 and label=0\n",
            "  This document represents the proceedings of the 2024 XCSP3 Competition. The\n",
            "results of this competition of constraint solvers were presented at CP'24 (30th\n",
            "International Conference on Principles and Practice of Constraint Programming).\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2877 and label=0\n",
            "  Transformers, especially the decoder-only variants, are the backbone of most\n",
            "modern large language models; yet we do not have much understanding of their\n",
            "expressive power except for the simple $1$-layer case.\n",
            "  Due to the difficulty of analyzing multi-layer models, all previous work\n",
            "relies on unproven complexity conjectures to show limitations for multi-layer\n",
            "Transformers. In this work, we prove the first $\\textit{unconditional}$ lower\n",
            "bound against multi-layer decoder-only transformers. For any constant $L$, we\n",
            "prove that any $L$-layer decoder-only transformer needs a polynomial model\n",
            "dimension ($n^{\\Omega(1)}$) to perform sequential composition of $L$ functions\n",
            "over an input of $n$ tokens.\n",
            "  As a consequence, our results give: (1) the first depth-width trade-off for\n",
            "multi-layer transformers, exhibiting that the $L$-step composition task is\n",
            "exponentially harder for $L$-layer models compared to $(L+1)$-layer ones; (2)\n",
            "an unconditional separation between encoder and decoder, exhibiting a hard task\n",
            "for decoders that can be solved by an exponentially shallower and smaller\n",
            "encoder; (3) a provable advantage of chain-of-thought, exhibiting a task that\n",
            "becomes exponentially easier with chain-of-thought.\n",
            "  On the technical side, we propose the multi-party $\\textit{autoregressive}$\n",
            "$\\textit{communication}$ $\\textit{model}$ that captures the computation of a\n",
            "decoder-only Transformer. We also introduce a new proof technique that finds a\n",
            "certain $\\textit{indistinguishable}$ $\\textit{decomposition}$ of all possible\n",
            "inputs iteratively for proving lower bounds in this model. We believe our new\n",
            "communication model and proof technique will be helpful to further understand\n",
            "the computational power of transformers.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2066 and label=0\n",
            "  Due to reasons of convenience and lack of tech literacy, transliteration\n",
            "(i.e., Romanizing native scripts instead of using localization tools) is\n",
            "eminently prevalent in the context of low-resource languages such as Sinhala,\n",
            "which have their own writing script. In this study, our focus is on Romanized\n",
            "Sinhala transliteration. We propose two methods to address this problem: Our\n",
            "baseline is a rule-based method, which is then compared against our second\n",
            "method where we approach the transliteration problem as a sequence-to-sequence\n",
            "task akin to the established Neural Machine Translation (NMT) task. For the\n",
            "latter, we propose a Transformer-based Encode-Decoder solution. We witnessed\n",
            "that the Transformer-based method could grab many ad-hoc patterns within the\n",
            "Romanized scripts compared to the rule-based method. The code base associated\n",
            "with this paper is available on GitHub -\n",
            "https://github.com/kasunw22/Sinhala-Transliterator/\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2526 and label=0\n",
            "  Language models have proven successful across a wide range of software\n",
            "engineering tasks, but their significant computational costs often hinder their\n",
            "practical adoption. To address this challenge, researchers have begun applying\n",
            "various compression strategies to improve the efficiency of language models for\n",
            "code. These strategies aim to optimize inference latency and memory usage,\n",
            "though often at the cost of reduced model effectiveness. However, there is\n",
            "still a significant gap in understanding how these strategies influence the\n",
            "efficiency and effectiveness of language models for code. Here, we empirically\n",
            "investigate the impact of three well-known compression strategies -- knowledge\n",
            "distillation, quantization, and pruning -- across three different classes of\n",
            "software engineering tasks: vulnerability detection, code summarization, and\n",
            "code search. Our findings reveal that the impact of these strategies varies\n",
            "greatly depending on the task and the specific compression method employed.\n",
            "Practitioners and researchers can use these insights to make informed decisions\n",
            "when selecting the most appropriate compression strategy, balancing both\n",
            "efficiency and effectiveness based on their specific needs.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2605 and label=0\n",
            "  Retrieval-Augmented Generation (RAG) architectures have recently garnered\n",
            "significant attention for their ability to improve truth grounding and\n",
            "coherence in natural language processing tasks. However, the reliability of RAG\n",
            "systems in producing accurate answers diminishes as the volume of data they\n",
            "access increases. Even with smaller datasets, these systems occasionally fail\n",
            "to address simple queries. This issue arises from their dependence on\n",
            "state-of-the-art large language models (LLMs), which can introduce uncertainty\n",
            "into the system's outputs. In this work, I propose a novel Comparative RAG\n",
            "system that introduces an evaluator module to bridge the gap between\n",
            "probabilistic RAG systems and deterministically verifiable responses. The\n",
            "evaluator compares external recommendations with the retrieved document chunks,\n",
            "adding a decision-making layer that enhances the system's reliability. This\n",
            "approach ensures that the chunks retrieved are both semantically relevant and\n",
            "logically consistent with deterministic insights, thereby improving the\n",
            "accuracy and overall efficiency of RAG systems. This framework paves the way\n",
            "for more reliable and scalable question-answering applications in domains\n",
            "requiring high precision and verifiability.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.3164 and label=0\n",
            "  Code-mixing is the practice of using two or more languages in a single\n",
            "sentence, which often occurs in multilingual communities such as India where\n",
            "people commonly speak multiple languages. Classic NLP tools, trained on\n",
            "monolingual data, face challenges when dealing with code-mixed data. Extracting\n",
            "meaningful information from sentences containing multiple languages becomes\n",
            "difficult, particularly in tasks like hate speech detection, due to linguistic\n",
            "variation, cultural nuances, and data sparsity. To address this, we aim to\n",
            "analyze the significance of code-mixed embeddings and evaluate the performance\n",
            "of BERT and HingBERT models (trained on a Hindi-English corpus) in hate speech\n",
            "detection. Our study demonstrates that HingBERT models, benefiting from\n",
            "training on the extensive Hindi-English dataset L3Cube-HingCorpus, outperform\n",
            "BERT models when tested on hate speech text datasets. We also found that\n",
            "code-mixed Hing-FastText performs better than standard English FastText and\n",
            "vanilla BERT models.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.5041 and label=0\n",
            "  The rapid spread of information in the digital age highlights the critical\n",
            "need for effective fact-checking tools, particularly for languages with limited\n",
            "resources, such as Vietnamese. In response to this challenge, we introduce\n",
            "ViFactCheck, the first publicly available benchmark dataset designed\n",
            "specifically for Vietnamese fact-checking across multiple online news domains.\n",
            "This dataset contains 7,232 human-annotated pairs of claim-evidence\n",
            "combinations sourced from reputable Vietnamese online news, covering 12 diverse\n",
            "topics. It has been subjected to a meticulous annotation process to ensure high\n",
            "quality and reliability, achieving a Fleiss Kappa inter-annotator agreement\n",
            "score of 0.83. Our evaluation leverages state-of-the-art pre-trained and large\n",
            "language models, employing fine-tuning and prompting techniques to assess\n",
            "performance. Notably, the Gemma model demonstrated superior effectiveness, with\n",
            "an impressive macro F1 score of 89.90%, thereby establishing a new standard for\n",
            "fact-checking benchmarks. This result highlights the robust capabilities of\n",
            "Gemma in accurately identifying and verifying facts in Vietnamese. To further\n",
            "promote advances in fact-checking technology and improve the reliability of\n",
            "digital media, we have made the ViFactCheck dataset, model checkpoints,\n",
            "fact-checking pipelines, and source code freely available on GitHub. This\n",
            "initiative aims to inspire further research and enhance the accuracy of\n",
            "information in low-resource languages.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2754 and label=0\n",
            "  Recent generative large language models (LLMs) show remarkable performance in\n",
            "non-English languages, but when prompted in those languages they tend to\n",
            "express higher harmful social biases and toxicity levels. Prior work has shown\n",
            "that finetuning on specialized datasets can mitigate this behavior, and doing\n",
            "so in English can transfer to other languages. In this work, we investigate the\n",
            "impact of different finetuning methods on the model's bias and toxicity, but\n",
            "also on its ability to produce fluent and diverse text. Our results show that\n",
            "finetuning on curated non-harmful text is more effective for mitigating bias,\n",
            "and finetuning on direct preference optimization (DPO) datasets is more\n",
            "effective for mitigating toxicity. The mitigation caused by applying these\n",
            "methods in English also transfers to non-English languages. We find evidence\n",
            "that the extent to which transfer takes place can be predicted by the amount of\n",
            "data in a given language present in the model's pretraining data. However, this\n",
            "transfer of bias and toxicity mitigation often comes at the expense of\n",
            "decreased language generation ability in non-English languages, highlighting\n",
            "the importance of developing language-specific bias and toxicity mitigation\n",
            "methods.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2248 and label=0\n",
            "  The philosophy of language, which has historically been developed through an\n",
            "anthropocentric lens, is now being forced to move towards post-anthropocentrism\n",
            "due to the advent of large language models (LLMs) like ChatGPT (OpenAI), Claude\n",
            "(Anthropic), which are considered to possess linguistic abilities comparable to\n",
            "those of humans. Traditionally, LLMs have been explained through distributional\n",
            "semantics as their foundational semantics. However, recent research is\n",
            "exploring alternative foundational semantics beyond distributional semantics.\n",
            "This paper proposes Robert Brandom's inferentialist semantics as an suitable\n",
            "foundational semantics for LLMs, specifically focusing on the issue of\n",
            "linguistic representationalism within this post-anthropocentric trend. Here, we\n",
            "show that the anti-representationalism and logical expressivism of inferential\n",
            "semantics, as well as quasi-compositionality, are useful in interpreting the\n",
            "characteristics and behaviors of LLMs. Further, we propose a \\emph{consensus\n",
            "theory of truths} for LLMs. This paper argues that the characteristics of LLMs\n",
            "challenge mainstream assumptions in philosophy of language, such as semantic\n",
            "externalism and compositionality. We believe the argument in this paper leads\n",
            "to a re-evaluation of anti\\hyphen{}representationalist views of language,\n",
            "potentially leading to new developments in the philosophy of language.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.1972 and label=0\n",
            "  Large Language Models (LLMs) are typically trained to predict in the forward\n",
            "direction of time. However, recent works have shown that prompting these models\n",
            "to look back and critique their own generations can produce useful feedback.\n",
            "Motivated by this, we explore the question of whether LLMs can be empowered to\n",
            "think (predict and score) backwards to provide unsupervised feedback that\n",
            "complements forward LLMs. Towards this, we introduce Time Reversed Language\n",
            "Models (TRLMs), which can score and generate queries when conditioned on\n",
            "responses, effectively functioning in the reverse direction of time. Further,\n",
            "to effectively infer in the response to query direction, we pre-train and\n",
            "fine-tune a language model (TRLM-Ba) in the reverse token order from scratch.\n",
            "We show empirically (and theoretically in a stylized setting) that\n",
            "time-reversed models can indeed complement forward model predictions when used\n",
            "to score the query given response for re-ranking multiple forward generations.\n",
            "We obtain up to 5\\% improvement on the widely used AlpacaEval Leaderboard over\n",
            "the competent baseline of best-of-N re-ranking using self log-perplexity\n",
            "scores. We further show that TRLM scoring outperforms conventional forward\n",
            "scoring of response given query, resulting in significant gains in applications\n",
            "such as citation generation and passage retrieval. We next leverage the\n",
            "generative ability of TRLM to augment or provide unsupervised feedback to input\n",
            "safety filters of LLMs, demonstrating a drastic reduction in false negative\n",
            "rate with negligible impact on false positive rates against several attacks\n",
            "published on the popular JailbreakBench leaderboard.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.7728 and label=0\n",
            "  Large language models (LLMs) have demonstrated strong capabilities in text\n",
            "understanding and generation. However, they often lack factuality, producing a\n",
            "mixture of true and false information, especially in long-form generation. In\n",
            "this work, we investigates the factuality of long-form text generation across\n",
            "various large language models (LLMs), including GPT-4, Gemini-1.5-Pro,\n",
            "Claude-3-Opus, Llama-3-70B, and Mistral. Our analysis reveals that factuality\n",
            "scores tend to decline in later sentences of the generated text, accompanied by\n",
            "a rise in the number of unsupported claims. Furthermore, we explore the\n",
            "effectiveness of different evaluation settings to assess whether LLMs can\n",
            "accurately judge the correctness of their own outputs: Self-Known (the\n",
            "percentage of supported atomic claims, decomposed from LLM outputs, that the\n",
            "corresponding LLMs judge as correct) and Self-Unknown (the percentage of\n",
            "unsupported atomic claims that the corresponding LLMs judge as incorrect). The\n",
            "results indicate that even advanced models like GPT-4 and Gemini-1.5-Pro fail\n",
            "to achieve perfect Self-Known scores, while their Self-Unknown scores remain\n",
            "notably above zero, reflecting ongoing uncertainty in their self-assessments.\n",
            "Moreover, we find a correlation between higher Self-Known scores and improved\n",
            "factuality, while higher Self-Unknown scores are associated with lower\n",
            "factuality. Interestingly, even without significant changes in the models'\n",
            "self-judgment (Self-Known and Self-Unknown), the number of unsupported claims\n",
            "can increases, likely as an artifact of long-form generation. These findings\n",
            "show the limitations of current LLMs in long-form generation, and provide\n",
            "valuable insights for improving factuality in long-form text generation.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.19 and label=0\n",
            "  Evaluating the capability of Large Language Models (LLMs) in following\n",
            "instructions has heavily relied on a powerful LLM as the judge, introducing\n",
            "unresolved biases that deviate the judgments from human judges. In this work,\n",
            "we reevaluate various choices for automatic evaluation on a wide range of\n",
            "instruction-following tasks. We experiment with methods that leverage\n",
            "human-written responses and observe that they enhance the reliability of\n",
            "automatic evaluations across a wide range of tasks, resulting in up to a 3.2%\n",
            "improvement in agreement with human judges. We also discovered that\n",
            "human-written responses offer an orthogonal perspective to model-generated\n",
            "responses in following instructions and should be used as an additional context\n",
            "when comparing model responses. Based on these observations, we develop a new\n",
            "evaluation benchmark, Human Response-Guided Evaluation of Instruction Following\n",
            "(HREF), comprising 4,258 samples across 11 task categories with a composite\n",
            "evaluation setup, employing a composite evaluation setup that selects the most\n",
            "reliable method for each category. In addition to providing reliable\n",
            "evaluation, HREF emphasizes individual task performance and is free from\n",
            "contamination. Finally, we study the impact of key design choices in HREF,\n",
            "including the size of the evaluation set, the judge model, the baseline model,\n",
            "and the prompt template. We host a live leaderboard that evaluates LLMs on the\n",
            "private evaluation set of HREF.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.238 and label=0\n",
            "  To combat the rising energy consumption of recommender systems we implement a\n",
            "novel alternative for k-fold cross validation. This alternative, named e-fold\n",
            "cross validation, aims to minimize the number of folds to achieve a reduction\n",
            "in power usage while keeping the reliability and robustness of the test results\n",
            "high. We tested our method on 5 recommender system algorithms across 6 datasets\n",
            "and compared it with 10-fold cross validation. On average e-fold cross\n",
            "validation only needed 41.5% of the energy that 10-fold cross validation would\n",
            "need, while it's results only differed by 1.81%. We conclude that e-fold cross\n",
            "validation is a promising approach that has the potential to be an energy\n",
            "efficient but still reliable alternative to k-fold cross validation.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2577 and label=0\n",
            "  We study to which extent additive fairness metrics (statistical parity, equal\n",
            "opportunity and equalized odds) can be influenced in a multi-class\n",
            "classification problem by memorizing a subset of the population. We give\n",
            "explicit expressions for the bias resulting from memorization in terms of the\n",
            "label and group membership distribution of the memorized dataset and the\n",
            "classifier bias on the unmemorized dataset. We also characterize the memorized\n",
            "datasets that eliminate the bias for all three metrics considered. Finally we\n",
            "provide upper and lower bounds on the total probability mass in the memorized\n",
            "dataset that is necessary for the complete elimination of these biases.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.5873 and label=0\n",
            "  The SQL-to-text generation task traditionally uses template base, Seq2Seq,\n",
            "tree-to-sequence, and graph-to-sequence models. Recent models take advantage of\n",
            "pre-trained generative language models for this task in the Seq2Seq framework.\n",
            "However, treating SQL as a sequence of inputs to the pre-trained models is not\n",
            "optimal. In this work, we put forward a new SQL intermediate representation\n",
            "called EzSQL to align SQL with the natural language text sequence. EzSQL\n",
            "simplifies the SQL queries and brings them closer to natural language text by\n",
            "modifying operators and keywords, which can usually be described in natural\n",
            "language. EzSQL also removes the need for set operators. Our proposed\n",
            "SQL-to-text generation model uses EzSQL as the input to a pre-trained\n",
            "generative language model for generating the text descriptions. We demonstrate\n",
            "that our model is an effective state-of-the-art method to generate text\n",
            "narrations from SQL queries on the WikiSQL and Spider datasets. We also show\n",
            "that by generating pretraining data using our SQL-to-text generation model, we\n",
            "can enhance the performance of Text-to-SQL parsers.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.5357 and label=0\n",
            "  The textual adversarial attack refers to an attack method in which the\n",
            "attacker adds imperceptible perturbations to the original texts by elaborate\n",
            "design so that the NLP (natural language processing) model produces false\n",
            "judgments. This method is also used to evaluate the robustness of NLP models.\n",
            "Currently, most of the research in this field focuses on English, and there is\n",
            "also a certain amount of research on Chinese. However, to the best of our\n",
            "knowledge, there is little research targeting Chinese minority languages.\n",
            "Textual adversarial attacks are a new challenge for the information processing\n",
            "of Chinese minority languages. In response to this situation, we propose a\n",
            "Tibetan syllable-level black-box textual adversarial attack called TSAttacker\n",
            "based on syllable cosine distance and scoring mechanism. And then, we conduct\n",
            "TSAttacker on six models generated by fine-tuning two PLMs (pre-trained\n",
            "language models) for three downstream tasks. The experiment results show that\n",
            "TSAttacker is effective and generates high-quality adversarial samples. In\n",
            "addition, the robustness of the involved models still has much room for\n",
            "improvement.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.3265 and label=0\n",
            "  We introduce a new class of neural networks designed to be convex functions\n",
            "of their inputs, leveraging the principle that any convex function can be\n",
            "represented as the supremum of the affine functions it dominates. These neural\n",
            "networks, inherently convex with respect to their inputs, are particularly\n",
            "well-suited for approximating the prices of options with convex payoffs. We\n",
            "detail the architecture of this, and establish theoretical convergence bounds\n",
            "that validate its approximation capabilities. We also introduce a\n",
            "\\emph{scrambling} phase to improve the training of these networks. Finally, we\n",
            "demonstrate numerically the effectiveness of these networks in estimating\n",
            "prices for three types of options with convex payoffs: Basket, Bermudan, and\n",
            "Swing options.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2502 and label=0\n",
            "  This paper compares the accuracy of the terms extracted using SketchEngine,\n",
            "TBXTools and ChatGPT. In addition, it evaluates the quality of the definitions\n",
            "produced by ChatGPT for these terms. The research is carried out on a\n",
            "comparable corpus of fashion magazines written in English and Russian collected\n",
            "from the web. A gold standard for the fashion terminology was also developed by\n",
            "identifying web pages that can be harvested automatically and contain\n",
            "definitions of terms from the fashion domain in English and Russian. This gold\n",
            "standard was used to evaluate the quality of the extracted terms and of the\n",
            "definitions produced. Our evaluation shows that TBXTools and SketchEngine,\n",
            "while capable of high recall, suffer from reduced precision as the number of\n",
            "terms increases, which affects their overall performance. Conversely, ChatGPT\n",
            "demonstrates superior performance, maintaining or improving precision as more\n",
            "terms are considered. Analysis of the definitions produced by ChatGPT for 60\n",
            "commonly used terms in English and Russian shows that ChatGPT maintains a\n",
            "reasonable level of accuracy and fidelity across languages, but sometimes the\n",
            "definitions in both languages miss crucial specifics and include unnecessary\n",
            "deviations. Our research reveals that no single tool excels universally; each\n",
            "has strengths suited to particular aspects of terminology extraction and\n",
            "application.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.3687 and label=0\n",
            "  Within computing research, there are two spellings for an increasingly\n",
            "important term - dialogue and dialog. We analyze thousands of research papers\n",
            "to understand this \"dialog(ue) debacle\". Among publications in top venues that\n",
            "use \"dialog(ue)\" in the title or abstract, 72% use \"dialogue\", 24% use\n",
            "\"dialog\", and 5% use both in the same title and abstract. This split\n",
            "distribution is more common in Computing than any other academic discipline. We\n",
            "investigate trends over ~20 years of NLP/AI research, not finding clear\n",
            "evidence of a shift over time. Author nationality is weakly correlated with\n",
            "spelling choice, but far from explains the mixed use. Many prolific authors\n",
            "publish papers with both spellings. We use several methods (such as syntactic\n",
            "parses and LM embeddings) to study how dialog(ue) context influences spelling,\n",
            "finding limited influence. Combining these results together, we discuss\n",
            "different theories that might explain the dialog(ue) divergence.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2422 and label=0\n",
            "  Large Language Models (LLMs) have demonstrated remarkable capabilities on\n",
            "various tasks, while the further evolvement is limited to the lack of\n",
            "high-quality training data. In addition, traditional training approaches rely\n",
            "too much on expert-labeled data, setting an upper limit on the performance of\n",
            "LLMs. To address this issue, we propose a novel paradigm that enables LLMs to\n",
            "train itself by autonomously generating, cleaning, reviewing, and annotating\n",
            "data with preference information, named LANCE. Our approach demonstrates that\n",
            "LLMs can serve as continuous self-evolving data engineers, significantly\n",
            "reducing the time and cost of the post-training data construction process.\n",
            "Through iterative fine-tuning on different variants of the Qwen2, we validate\n",
            "the effectiveness of LANCE across various tasks, showing that it can\n",
            "continuously improve model performance and maintain high-quality data\n",
            "generation. Across eight benchmark dimensions, LANCE resulted in an average\n",
            "score enhancement of 3.36 for Qwen2-7B and 2.70 for Qwen2-7B-Instruct. This\n",
            "training paradigm with autonomous data construction not only reduces the\n",
            "reliance on human experts or external models but also ensures that the data\n",
            "aligns with human values and preferences, paving the way for the development of\n",
            "future superintelligent systems that can exceed human capabilities.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.3905 and label=0\n",
            "  Active Curriculum Language Modeling (ACLM; Hong et al., 2023) is a learner\n",
            "directed approach to training a language model. We proposed the original\n",
            "version of this process in our submission to the BabyLM 2023 task, and now we\n",
            "propose an updated ACLM process for the BabyLM 2024 task. ACLM involves an\n",
            "iteratively- and dynamically-constructed curriculum informed over the training\n",
            "process by a model of uncertainty; other training items that are similarly\n",
            "uncertain to a least certain candidate item are prioritized. Our new process\n",
            "improves the similarity model so that it is more dynamic, and we run ACLM over\n",
            "the most successful model from the BabyLM 2023 task: ELC-BERT (Charpentier and\n",
            "Samuel, 2023). We find that while our models underperform on fine-grained\n",
            "grammatical inferences, they outperform the BabyLM 2024 official base-lines on\n",
            "common-sense and world-knowledge tasks. We make our code available at https:\n",
            "//github.com/asayeed/ActiveBaby.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.3014 and label=0\n",
            "  Bias studies on multilingual models confirm the presence of gender-related\n",
            "stereotypes in masked models processing languages with high NLP resources. We\n",
            "expand on this line of research by introducing Filipino CrowS-Pairs and\n",
            "Filipino WinoQueer: benchmarks that assess both sexist and anti-queer biases in\n",
            "pretrained language models (PLMs) handling texts in Filipino, a low-resource\n",
            "language from the Philippines. The benchmarks consist of 7,074 new challenge\n",
            "pairs resulting from our cultural adaptation of English bias evaluation\n",
            "datasets, a process that we document in detail to guide similar forthcoming\n",
            "efforts. We apply the Filipino benchmarks on masked and causal multilingual\n",
            "models, including those pretrained on Southeast Asian data, and find that they\n",
            "contain considerable amounts of bias. We also find that for multilingual\n",
            "models, the extent of bias learned for a particular language is influenced by\n",
            "how much pretraining data in that language a model was exposed to. Our\n",
            "benchmarks and insights can serve as a foundation for future work analyzing and\n",
            "mitigating bias in multilingual models.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.3173 and label=0\n",
            "  Several power-law critical properties involving different statistics in\n",
            "natural languages -- reminiscent of scaling properties of physical systems at\n",
            "or near phase transitions -- have been documented for decades.\n",
            "  The recent rise of large language models (LLMs) has added further evidence\n",
            "and excitement by providing intriguing similarities with notions in physics\n",
            "such as scaling laws and emergent abilities.\n",
            "  However, specific instances of classes of generative language models that\n",
            "exhibit phase transitions, as understood by the statistical physics community,\n",
            "are lacking.\n",
            "  In this work, inspired by the one-dimensional Potts model in statistical\n",
            "physics we construct a simple probabilistic language model that falls under the\n",
            "class of context sensitive grammars (CSG), and numerically demonstrate an\n",
            "unambiguous phase transition in the framework of a natural language model.\n",
            "  We explicitly show that a precisely defined order parameter -- that captures\n",
            "symbol frequency biases in the sentences generated by the language model --\n",
            "changes from strictly 0 to a strictly nonzero value (in the infinite-length\n",
            "limit of sentences), implying a mathematical singularity arising when tuning\n",
            "the parameter of the stochastic language model we consider.\n",
            "  Furthermore, we identify the phase transition as a variant of the\n",
            "Berezinskii-Kosterlitz-Thouless (BKT) transition, which is known to exhibit\n",
            "critical properties not only at the transition point but also in the entire\n",
            "phase.\n",
            "  This finding leads to the possibility that critical properties in natural\n",
            "languages may not require careful fine-tuning nor self-organized criticality,\n",
            "but is generically explained by the underlying connection between language\n",
            "structures and the BKT phases.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.222 and label=0\n",
            "  Sentence-level embedding is essential for various tasks that require\n",
            "understanding natural language. Many studies have explored such embeddings for\n",
            "high-resource languages like English. However, low-resource languages like\n",
            "Bengali (a language spoken by almost two hundred and thirty million people) are\n",
            "still under-explored. This work introduces two lightweight sentence\n",
            "transformers for the Bangla language, leveraging a novel cross-lingual\n",
            "knowledge distillation approach. This method distills knowledge from a\n",
            "pre-trained, high-performing English sentence transformer. Proposed models are\n",
            "evaluated across multiple downstream tasks, including paraphrase detection,\n",
            "semantic textual similarity (STS), and Bangla hate speech detection. The new\n",
            "method consistently outperformed existing Bangla sentence transformers.\n",
            "Moreover, the lightweight architecture and shorter inference time make the\n",
            "models highly suitable for deployment in resource-constrained environments,\n",
            "making them valuable for practical NLP applications in low-resource languages.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.1992 and label=0\n",
            "  The unwavering disparity in labeled resources between resource-rich languages\n",
            "and those considered low-resource remains a significant impediment for Large\n",
            "Language Models (LLMs). Recent strides in cross-lingual in-context learning\n",
            "(X-ICL), mainly through semantically aligned examples retrieved from\n",
            "multilingual pre-trained transformers, have shown promise in mitigating this\n",
            "issue. However, our investigation reveals that LLMs intrinsically reward\n",
            "in-language semantically aligned cross-lingual instances over direct\n",
            "cross-lingual semantic alignments, with a pronounced disparity in handling\n",
            "time-sensitive queries in the X-ICL setup. Such queries demand sound temporal\n",
            "reasoning ability from LLMs, yet the advancements have predominantly focused on\n",
            "English. This study aims to bridge this gap by improving temporal reasoning\n",
            "capabilities in low-resource languages. To this end, we introduce mTEMPREASON a\n",
            "temporal reasoning dataset aimed at the varied degrees of low-resource\n",
            "languages and propose Cross-Lingual Time-Sensitive Semantic Alignment\n",
            "(CLiTSSA), a novel method to improve temporal reasoning in these contexts. To\n",
            "facilitate this, we construct an extension of mTEMPREASON comprising pairs of\n",
            "parallel cross-language temporal queries along with their anticipated\n",
            "in-language semantic similarity scores. Our empirical evidence underscores the\n",
            "superior performance of CLiTSSA compared to established baselines across three\n",
            "languages - Romanian, German, and French, encompassing three temporal tasks and\n",
            "including a diverse set of four contemporaneous LLMs. This marks a significant\n",
            "step forward in addressing resource disparity in the context of temporal\n",
            "reasoning across languages.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.1936 and label=0\n",
            "  As events progress, news articles often update with new information: if we\n",
            "are not cautious, we risk propagating outdated facts. In this work, we\n",
            "hypothesize that linguistic features indicate factual fluidity, and that we can\n",
            "predict which facts in a news article will update using solely the text of a\n",
            "news article (i.e. not external resources like search engines). We test this\n",
            "hypothesis, first, by isolating fact-updates in large news revisions corpora.\n",
            "News articles may update for many reasons (e.g. factual, stylistic, narrative).\n",
            "We introduce the NewsEdits 2.0 taxonomy, an edit-intentions schema that\n",
            "separates fact updates from stylistic and narrative updates in news writing. We\n",
            "annotate over 9,200 pairs of sentence revisions and train high-scoring ensemble\n",
            "models to apply this schema. Then, taking a large dataset of silver-labeled\n",
            "pairs, we show that we can predict when facts will update in older article\n",
            "drafts with high precision. Finally, to demonstrate the usefulness of these\n",
            "findings, we construct a language model question asking (LLM-QA) abstention\n",
            "task. We wish the LLM to abstain from answering questions when information is\n",
            "likely to become outdated. Using our predictions, we show, LLM absention\n",
            "reaches near oracle levels of accuracy.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.3519 and label=0\n",
            "  Large language models (LLMs) have learned vast amounts of factual knowledge\n",
            "through self-supervised pre-training on large-scale corpora. Meanwhile, LLMs\n",
            "have also demonstrated excellent multilingual capabilities, which can express\n",
            "the learned knowledge in multiple languages. However, the knowledge storage\n",
            "mechanism in LLMs still remains mysterious. Some researchers attempt to\n",
            "demystify the factual knowledge in LLMs from the perspective of knowledge\n",
            "neurons, and subsequently discover language-agnostic knowledge neurons that\n",
            "store factual knowledge in a form that transcends language barriers. However,\n",
            "the preliminary finding suffers from two limitations: 1) High Uncertainty in\n",
            "Localization Results. Existing study only uses a prompt-based probe to localize\n",
            "knowledge neurons for each fact, while LLMs cannot provide consistent answers\n",
            "for semantically equivalent queries. Thus, it leads to inaccurate localization\n",
            "results with high uncertainty. 2) Lack of Analysis in More Languages. The study\n",
            "only analyzes language-agnostic knowledge neurons on English and Chinese data,\n",
            "without exploring more language families and languages. Naturally, it limits\n",
            "the generalizability of the findings. To address aforementioned problems, we\n",
            "first construct a new benchmark called Rephrased Multilingual LAMA (RML-LAMA),\n",
            "which contains high-quality cloze-style multilingual parallel queries for each\n",
            "fact. Then, we propose a novel method named Multilingual Integrated Gradients\n",
            "with Uncertainty Estimation (MATRICE), which quantifies the uncertainty across\n",
            "queries and languages during knowledge localization. Extensive experiments show\n",
            "that our method can accurately localize language-agnostic knowledge neurons. We\n",
            "also further investigate the role of language-agnostic knowledge neurons in\n",
            "cross-lingual knowledge editing, knowledge enhancement and new knowledge\n",
            "injection.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.3452 and label=0\n",
            "  In Extreme Multi Label Completion (XMLCo), the objective is to predict the\n",
            "missing labels of a collection of documents. Together with XML Classification,\n",
            "XMLCo is arguably one of the most challenging document classification tasks, as\n",
            "the very high number of labels (at least ten of thousands) is generally very\n",
            "large compared to the number of available labelled documents in the training\n",
            "dataset. Such a task is often accompanied by a taxonomy that encodes the labels\n",
            "organic relationships, and many methods have been proposed to leverage this\n",
            "hierarchy to improve the results of XMLCo algorithms. In this paper, we propose\n",
            "a new approach to this problem, TAMLEC (Taxonomy-Aware Multi-task Learning for\n",
            "Extreme multi-label Completion). TAMLEC divides the problem into several\n",
            "Taxonomy-Aware Tasks, i.e. subsets of labels adapted to the hierarchical paths\n",
            "of the taxonomy, and trains on these tasks using a dynamic Parallel Feature\n",
            "sharing approach, where some parts of the model are shared between tasks while\n",
            "others are task-specific. Then, at inference time, TAMLEC uses the labels\n",
            "available in a document to infer the appropriate tasks and to predict missing\n",
            "labels. To achieve this result, TAMLEC uses a modified transformer architecture\n",
            "that predicts ordered sequences of labels on a Weak-Semilattice structure that\n",
            "is naturally induced by the tasks. This approach yields multiple advantages.\n",
            "First, our experiments on real-world datasets show that TAMLEC outperforms\n",
            "state-of-the-art methods for various XMLCo problems. Second, TAMLEC is by\n",
            "construction particularly suited for few-shots XML tasks, where new tasks or\n",
            "labels are introduced with only few examples, and extensive evaluations\n",
            "highlight its strong performance compared to existing methods.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2316 and label=0\n",
            "  Low-rank adapters have become a standard approach for efficiently fine-tuning\n",
            "large language models (LLMs), but they often fall short of achieving the\n",
            "performance of full fine-tuning. We propose a method, LoRA Silver Bullet or\n",
            "LoRA-SB, that approximates full fine-tuning within low-rank subspaces using a\n",
            "carefully designed initialization strategy. We theoretically demonstrate that\n",
            "the architecture of LoRA-XS, which inserts a trainable (r x r) matrix between B\n",
            "and A while keeping other matrices fixed, provides the precise conditions\n",
            "needed for this approximation. We leverage its constrained update space to\n",
            "achieve optimal scaling for high-rank gradient updates while removing the need\n",
            "for hyperparameter tuning. We prove that our initialization offers an optimal\n",
            "low-rank approximation of the initial gradient and preserves update directions\n",
            "throughout training. Extensive experiments across mathematical reasoning,\n",
            "commonsense reasoning, and language understanding tasks demonstrate that our\n",
            "approach exceeds the performance of standard LoRA while using 27-90x fewer\n",
            "parameters, and comprehensively outperforms LoRA-XS. Our findings establish\n",
            "that it is possible to simulate full fine-tuning in low-rank subspaces, and\n",
            "achieve significant efficiency gains without sacrificing performance. Our code\n",
            "is publicly available at https://github.com/RaghavSinghal10/lora-sb.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.3366 and label=0\n",
            "  In this work, we introduce the task of life-long personalization of large\n",
            "language models. While recent mainstream efforts in the LLM community mainly\n",
            "focus on scaling data and compute for improved capabilities of LLMs, we argue\n",
            "that it is also very important to enable LLM systems, or language agents, to\n",
            "continuously adapt to the diverse and ever-changing profiles of every distinct\n",
            "user and provide up-to-date personalized assistance. We provide a clear task\n",
            "formulation and introduce a simple, general, effective, and scalable framework\n",
            "for life-long personalization of LLM systems and language agents. To facilitate\n",
            "future research on LLM personalization, we also introduce methods to synthesize\n",
            "realistic benchmarks and robust evaluation metrics. We will release all codes\n",
            "and data for building and benchmarking life-long personalized LLM systems.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2407 and label=0\n",
            "  Large Language Models (LLMs) have demonstrated notable proficiency in both\n",
            "code generation and comprehension across multiple programming languages.\n",
            "However, the mechanisms underlying this proficiency remain underexplored,\n",
            "particularly with respect to whether distinct programming languages are\n",
            "processed independently or within a shared parametric region. Drawing an\n",
            "analogy to the specialized regions of the brain responsible for distinct\n",
            "cognitive functions, we introduce the concept of Coding Spot, a specialized\n",
            "parametric region within LLMs that facilitates coding capabilities. Our\n",
            "findings identify this Coding Spot and show that targeted modifications to this\n",
            "subset significantly affect performance on coding tasks, while largely\n",
            "preserving non-coding functionalities. This compartmentalization mirrors the\n",
            "functional specialization observed in cognitive neuroscience, where specific\n",
            "brain regions are dedicated to distinct tasks, suggesting that LLMs may\n",
            "similarly employ specialized parameter regions for different knowledge domains.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.1895 and label=0\n",
            "  Evaluation metric of visual captioning is important yet not thoroughly\n",
            "explored. Traditional metrics like BLEU, METEOR, CIDEr, and ROUGE often miss\n",
            "semantic depth, while trained metrics such as CLIP-Score, PAC-S, and Polos are\n",
            "limited in zero-shot scenarios. Advanced Language Model-based metrics also\n",
            "struggle with aligning to nuanced human preferences. To address these issues,\n",
            "we introduce G-VEval, a novel metric inspired by G-Eval and powered by the new\n",
            "GPT-4o. G-VEval uses chain-of-thought reasoning in large multimodal models and\n",
            "supports three modes: reference-free, reference-only, and combined,\n",
            "accommodating both video and image inputs. We also propose MSVD-Eval, a new\n",
            "dataset for video captioning evaluation, to establish a more transparent and\n",
            "consistent framework for both human experts and evaluation metrics. It is\n",
            "designed to address the lack of clear criteria in existing datasets by\n",
            "introducing distinct dimensions of Accuracy, Completeness, Conciseness, and\n",
            "Relevance (ACCR). Extensive results show that G-VEval outperforms existing\n",
            "methods in correlation with human annotations, as measured by Kendall tau-b and\n",
            "Kendall tau-c. This provides a flexible solution for diverse captioning tasks\n",
            "and suggests a straightforward yet effective approach for large language models\n",
            "to understand video content, paving the way for advancements in automated\n",
            "captioning. Codes are available at https://github.com/ztangaj/gveval\n",
            "\n",
            "-------------------------\n",
            "Proba=0.3456 and label=0\n",
            "  Recently, much work has concerned itself with the enigma of what exactly PLMs\n",
            "(pretrained language models) learn about different aspects of language, and how\n",
            "they learn it. One stream of this type of research investigates the knowledge\n",
            "that PLMs have about semantic relations. However, many aspects of semantic\n",
            "relations were left unexplored. Only one relation was considered, namely\n",
            "hypernymy. Furthermore, previous work did not measure humans' performance on\n",
            "the same task as that solved by the PLMs. This means that at this point in\n",
            "time, there is only an incomplete view of models' semantic relation knowledge.\n",
            "To address this gap, we introduce a comprehensive evaluation framework covering\n",
            "five relations beyond hypernymy, namely hyponymy, holonymy, meronymy, antonymy,\n",
            "and synonymy. We use six metrics (two newly introduced here) for recently\n",
            "untreated aspects of semantic relation knowledge, namely soundness,\n",
            "completeness, symmetry, asymmetry, prototypicality, and distinguishability and\n",
            "fairly compare humans and models on the same task. Our extensive experiments\n",
            "involve 16 PLMs, eight masked and eight causal language models. Up to now only\n",
            "masked language models had been tested although causal and masked language\n",
            "models treat context differently. Our results reveal a significant knowledge\n",
            "gap between humans and models for almost all semantic relations. Antonymy is\n",
            "the outlier relation where all models perform reasonably well. In general,\n",
            "masked language models perform significantly better than causal language\n",
            "models. Nonetheless, both masked and causal language models are likely to\n",
            "confuse non-antonymy relations with antonymy.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.7257 and label=0\n",
            "  The recent work of Kleinberg and Mullainathan [KM24] provides a concrete\n",
            "model for language generation in the limit: given a sequence of examples from\n",
            "an unknown target language, the goal is to generate new examples from the\n",
            "target language such that no incorrect examples are generated beyond some\n",
            "point. In sharp contrast to strong negative results for the closely related\n",
            "problem of language identification, they establish positive results for\n",
            "language generation in the limit for all countable collections of languages.\n",
            "Follow-up work by Raman and Tewari [RT24] studies bounds on the number of\n",
            "distinct inputs required by an algorithm before correct language generation is\n",
            "achieved -- namely, whether this is a constant for all languages in the\n",
            "collection (uniform generation) or a language-dependent constant (non-uniform\n",
            "generation).\n",
            "  We show that every countable language collection has a generator which has\n",
            "the stronger property of non-uniform generation in the limit. However, while\n",
            "the generation algorithm of [KM24] can be implemented using membership queries,\n",
            "we show that any algorithm cannot non-uniformly generate even for collections\n",
            "of just two languages, using only membership queries.\n",
            "  We also formalize the tension between validity and breadth in the generation\n",
            "algorithm of [KM24] by introducing a definition of exhaustive generation, and\n",
            "show a strong negative result for exhaustive generation. Our result shows that\n",
            "a tradeoff between validity and breadth is inherent for generation in the\n",
            "limit. Finally, inspired by algorithms that can choose to obtain feedback, we\n",
            "consider a model of uniform generation with feedback, completely characterizing\n",
            "language collections for which such uniform generation with feedback is\n",
            "possible in terms of a complexity measure of the collection.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2623 and label=0\n",
            "  In this project, we develop a practical and efficient solution for automating\n",
            "the Manhwa translation from Indonesian to English. Our approach combines\n",
            "computer vision, text recognition, and natural language processing techniques\n",
            "to streamline the traditionally manual process of Manhwa(Korean comics)\n",
            "translation. The pipeline includes fine-tuned YOLOv5xu for speech bubble\n",
            "detection, Tesseract for OCR and fine-tuned MarianMT for machine translation.\n",
            "By automating these steps, we aim to make Manhwa more accessible to a global\n",
            "audience while saving time and effort compared to manual translation methods.\n",
            "While most Manhwa translation efforts focus on Japanese-to-English, we focus on\n",
            "Indonesian-to-English translation to address the challenges of working with\n",
            "low-resource languages. Our model shows good results at each step and was able\n",
            "to translate from Indonesian to English efficiently.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.4463 and label=0\n",
            "  Human languages have evolved to be structured through repeated language\n",
            "learning and use. These processes introduce biases that operate during language\n",
            "acquisition and shape linguistic systems toward communicative efficiency. In\n",
            "this paper, we investigate whether the same happens if artificial languages are\n",
            "optimised for implicit biases of Large Language Models (LLMs). To this end, we\n",
            "simulate a classical referential game in which LLMs learn and use artificial\n",
            "languages. Our results show that initially unstructured holistic languages are\n",
            "indeed shaped to have some structural properties that allow two LLM agents to\n",
            "communicate successfully. Similar to observations in human experiments,\n",
            "generational transmission increases the learnability of languages, but can at\n",
            "the same time result in non-humanlike degenerate vocabularies. Taken together,\n",
            "this work extends experimental findings, shows that LLMs can be used as tools\n",
            "in simulations of language evolution, and opens possibilities for future\n",
            "human-machine experiments in this field.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.2934 and label=0\n",
            "  In this work, we explore a cost-effective framework for multilingual image\n",
            "generation. We find that, unlike models tuned on high-quality images with\n",
            "multilingual annotations, leveraging text encoders pre-trained on widely\n",
            "available, noisy Internet image-text pairs significantly enhances data\n",
            "efficiency in text-to-image (T2I) generation across multiple languages. Based\n",
            "on this insight, we introduce MuLan, Multi-Language adapter, a lightweight\n",
            "language adapter with fewer than 20M parameters, trained alongside a frozen\n",
            "text encoder and image diffusion model. Compared to previous multilingual T2I\n",
            "models, this framework offers: (1) Cost efficiency. Using readily accessible\n",
            "English data and off-the-shelf multilingual text encoders minimizes the\n",
            "training cost; (2) High performance. Achieving comparable generation\n",
            "capabilities in over 110 languages with CLIP similarity scores nearly matching\n",
            "those in English (38.61 for English vs. 37.61 for other languages); and (3)\n",
            "Broad applicability. Seamlessly integrating with compatible community tools\n",
            "like LoRA, LCM, ControlNet, and IP-Adapter, expanding its potential use cases.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.4128 and label=0\n",
            "  We present HadaCore, a modified Fast Walsh-Hadamard Transform (FWHT)\n",
            "algorithm optimized for the Tensor Cores present in modern GPU hardware.\n",
            "HadaCore follows the recursive structure of the original FWHT algorithm,\n",
            "achieving the same asymptotic runtime complexity but leveraging a\n",
            "hardware-aware work decomposition that benefits from Tensor Core acceleration.\n",
            "This reduces bottlenecks from compute and data exchange. On Nvidia A100 and\n",
            "H100 GPUs, HadaCore achieves speedups of 1.1-1.4x and 1.0-1.3x, with a peak\n",
            "gain of 3.5x and 3.6x respectively, when compared to the existing\n",
            "state-of-the-art implementation of the original algorithm. We also show that\n",
            "when using FP16 or BF16, our implementation is numerically accurate, enabling\n",
            "comparable accuracy on MMLU benchmarks when used in an end-to-end Llama3\n",
            "inference run with quantized (FP8) attention.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.4346 and label=0\n",
            "  This paper presents a multi-way parallel English-Tamil-Sinhala corpus\n",
            "annotated with Named Entities (NEs), where Sinhala and Tamil are low-resource\n",
            "languages. Using pre-trained multilingual Language Models (mLMs), we establish\n",
            "new benchmark Named Entity Recognition (NER) results on this dataset for\n",
            "Sinhala and Tamil. We also carry out a detailed investigation on the NER\n",
            "capabilities of different types of mLMs. Finally, we demonstrate the utility of\n",
            "our NER system on a low-resource Neural Machine Translation (NMT) task. Our\n",
            "dataset is publicly released: https://github.com/suralk/multiNER.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.5284 and label=0\n",
            "  Sycophancy refers to the tendency of a large language model to align its\n",
            "outputs with the user's perceived preferences, beliefs, or opinions, in order\n",
            "to look favorable, regardless of whether those statements are factually\n",
            "correct. This behavior can lead to undesirable consequences, such as\n",
            "reinforcing discriminatory biases or amplifying misinformation. Given that\n",
            "sycophancy is often linked to human feedback training mechanisms, this study\n",
            "explores whether sycophantic tendencies negatively impact user trust in large\n",
            "language models or, conversely, whether users consider such behavior as\n",
            "favorable. To investigate this, we instructed one group of participants to\n",
            "answer ground-truth questions with the assistance of a GPT specifically\n",
            "designed to provide sycophantic responses, while another group used the\n",
            "standard version of ChatGPT. Initially, participants were required to use the\n",
            "language model, after which they were given the option to continue using it if\n",
            "they found it trustworthy and useful. Trust was measured through both\n",
            "demonstrated actions and self-reported perceptions. The findings consistently\n",
            "show that participants exposed to sycophantic behavior reported and exhibited\n",
            "lower levels of trust compared to those who interacted with the standard\n",
            "version of the model, despite the opportunity to verify the accuracy of the\n",
            "model's output.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.6345 and label=0\n",
            "  We introduce FarExStance, a new dataset for explainable stance detection in\n",
            "Farsi. Each instance in this dataset contains a claim, the stance of an article\n",
            "or social media post towards that claim, and an extractive explanation which\n",
            "provides evidence for the stance label. We compare the performance of a\n",
            "fine-tuned multilingual RoBERTa model to several large language models in\n",
            "zero-shot, few-shot, and parameter-efficient fine-tuned settings on our new\n",
            "dataset. On stance detection, the most accurate models are the fine-tuned\n",
            "RoBERTa model, the LLM Aya-23-8B which has been fine-tuned using\n",
            "parameter-efficient fine-tuning, and few-shot Claude-3.5-Sonnet. Regarding the\n",
            "quality of the explanations, our automatic evaluation metrics indicate that\n",
            "few-shot GPT-4o generates the most coherent explanations, while our human\n",
            "evaluation reveals that the best Overall Explanation Score (OES) belongs to\n",
            "few-shot Claude-3.5-Sonnet. The fine-tuned Aya-32-8B model produced\n",
            "explanations most closely aligned with the reference explanations.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.287 and label=0\n",
            "  Question answering is a fundamental capability of large language models\n",
            "(LLMs). However, when people encounter completely new knowledge texts, they\n",
            "often ask questions that the text cannot answer due to a lack of understanding\n",
            "of the knowledge. Recent research shows that large language models identify the\n",
            "unanswerability of questions, but they lack the ability to help people\n",
            "reformulate their questions. Even powerful models like GPT-3.5 perform poorly\n",
            "in this regard. To enhance the ability of LLMs to assist humans in\n",
            "reformulating questions to extract relevant knowledge from new documents, we\n",
            "propose a zero-shot method called DRS: Deep Question Reformulation With\n",
            "Structured Output. Our proposed method leverages large language models and the\n",
            "DFS-based algorithm to iteratively search for possible entity combinations and\n",
            "constrain the output with certain entities, effectively improving the\n",
            "capabilities of large language models in this area. Extensive experimental\n",
            "results show that our zero-shot DRS method significantly improves the\n",
            "reformulation accuracy of GPT-3.5 from 23.03% to 70.42% and effectively\n",
            "improves the score of open-source large language models, such as Gemma2-9B,\n",
            "from 26.35% to 56.75%.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.5292 and label=0\n",
            "  This paper aims to provide a comparison between texts produced by French and\n",
            "Italian politicians on polarizing issues, such as immigration and the European\n",
            "Union, and their chatbot counterparts created with ChatGPT 3.5. In this study,\n",
            "we focus on implicit communication, in particular on presuppositions and their\n",
            "functions in discourse, which have been considered in the literature as a\n",
            "potential linguistic feature of manipulation. This study also aims to\n",
            "contribute to the emerging literature on the pragmatic competences of Large\n",
            "Language Models.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.7602 and label=0\n",
            "  I present Astro-HEP-BERT, a transformer-based language model specifically\n",
            "designed for generating contextualized word embeddings (CWEs) to study the\n",
            "meanings of concepts in astrophysics and high-energy physics. Built on a\n",
            "general pretrained BERT model, Astro-HEP-BERT underwent further training over\n",
            "three epochs using the Astro-HEP Corpus, a dataset I curated from 21.84 million\n",
            "paragraphs extracted from more than 600,000 scholarly articles on arXiv, all\n",
            "belonging to at least one of these two scientific domains. The project\n",
            "demonstrates both the effectiveness and feasibility of adapting a bidirectional\n",
            "transformer for applications in the history, philosophy, and sociology of\n",
            "science (HPSS). The entire training process was conducted using freely\n",
            "available code, pretrained weights, and text inputs, completed on a single\n",
            "MacBook Pro Laptop (M2/96GB). Preliminary evaluations indicate that\n",
            "Astro-HEP-BERT's CWEs perform comparably to domain-adapted BERT models trained\n",
            "from scratch on larger datasets for domain-specific word sense disambiguation\n",
            "and induction and related semantic change analyses. This suggests that\n",
            "retraining general language models for specific scientific domains can be a\n",
            "cost-effective and efficient strategy for HPSS researchers, enabling high\n",
            "performance without the need for extensive training from scratch.\n",
            "\n",
            "-------------------------\n",
            "Proba=0.3222 and label=0\n",
            "  This study proposes a qualitative analysis of self replies in Wikipedia talk\n",
            "pages, more precisely when the first two messages of a discussion are written\n",
            "by the same user. This specific pattern occurs in more than 10% of threads with\n",
            "two messages or more and can be explained by a number of reasons. After a first\n",
            "examination of the lexical specificities of second messages, we propose a seven\n",
            "categories typology and use it to annotate two reference samples (English and\n",
            "French) of 100 threads each. Finally, we analyse and compare the performance of\n",
            "human annotators (who reach a reasonable global efficiency) and\n",
            "instruction-tuned LLMs (which encounter important difficulties with several\n",
            "categories).\n",
            "\n",
            "-------------------------\n",
            "Proba=0.4373 and label=0\n",
            "  This thesis presents Abstractive Text Summarization models for contemporary\n",
            "Sanskrit prose. The first chapter, titled Introduction, presents the motivation\n",
            "behind this work, the research questions, and the conceptual framework.\n",
            "Sanskrit is a low-resource inflectional language. The key research question\n",
            "that this thesis investigates is what the challenges in developing an\n",
            "abstractive TS for Sanskrit. To answer the key research questions,\n",
            "sub-questions based on four different themes have been posed in this work. The\n",
            "second chapter, Literature Review, surveys the previous works done. The third\n",
            "chapter, data preparation, answers the remaining three questions from the third\n",
            "theme. It reports the data collection and preprocessing challenges for both\n",
            "language model and summarization model trainings. The fourth chapter reports\n",
            "the training and inference of models and the results obtained therein. This\n",
            "research has initiated a pipeline for Sanskrit abstractive text summarization\n",
            "and has reported the challenges faced at every stage of the development. The\n",
            "research questions based on every theme have been answered to answer the key\n",
            "research question.\n",
            "\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "best_threshold = evaluation[\"eval_threshold\"]\n",
        "y_pred = trainer.predict(validation_dataset)\n",
        "y_proba = 1/(1+np.exp(-y_pred.predictions))[:, 1]\n",
        "\n",
        "for (index, proba) in enumerate(y_proba):\n",
        "  if proba > best_threshold and val_labels[index] == 0:\n",
        "    print(f\"Proba={proba:.4} and label={val_labels[index]}\")\n",
        "    print(val_texts[index])\n",
        "    print(\"-\" * 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## To be continued\n",
        "\n",
        "This is the end of the notebook, one shall use it to fine-tune a model on its own use-case !"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "041c3da434d94dd1bdfbd46bdcf519eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f2a7bc17f604670be12bc567ddb2751",
              "IPY_MODEL_7bb3d0c1bce44fae80f006f5709b7b69",
              "IPY_MODEL_83630888910b456bafd9a67ac32fbcb1"
            ],
            "layout": "IPY_MODEL_498544775cac4691a8fae89d297c81d3"
          }
        },
        "04e0877932a14b1882294d76add72f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0af56e2ea96a4aa28816954ed32f914c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c388cb9342b4fbdaa35eca93d34e348": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f2a7bc17f604670be12bc567ddb2751": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21cb09527e224c059f061b906f7a841e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6c61fe0fde114560b301b7048f6a7e10",
            "value": "vocab.txt:â€‡100%"
          }
        },
        "15af3efaca7f462aa4aa9ce7e5c77178": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18b495ccac2e44e4abdaaf099a3b76a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b9f195298e44e69ad99cb5d8654c1d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d9d1d33bef2416380048c954f8495fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21cb09527e224c059f061b906f7a841e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21d010d256c849f1936978013596bee1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "255de73d638c4a569989b106e15909b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a2fef74bd624b7c88aea6b56988ad4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef64d246d81e4e91814932db4eba15fc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e5ccca2a3fc94980b19b985e7e6cc8fb",
            "value": "Map:â€‡100%"
          }
        },
        "2cfae7f1155e4ecba965be9f9bc180ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f3f9b4a39294e18b8b4d0d7cbc626a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_719cf28fc98c475d92591803e4e73f11",
            "max": 978,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2fd9d3cf96c450bb4c4ce2e7316a8cd",
            "value": 978
          }
        },
        "2f5eb807da904d629262cfcd8722dbd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "386eebf905f74f3e9a9f1e6c0ef6688a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b2a85015b574d049d006756cd0b9d87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c0e4dcd2820473f8c06769d534e9a78",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2cfae7f1155e4ecba965be9f9bc180ac",
            "value": "Map:â€‡100%"
          }
        },
        "3b63d9f2298a4e9da551bacaee024fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41102555060d4569a786cedcc785e9f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f392df123c9a42f2bf3eb6f9c5cb0b72",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9e2f19394dd24077a52a05b07abb7c99",
            "value": "â€‡440M/440Mâ€‡[00:02&lt;00:00,â€‡238MB/s]"
          }
        },
        "4282aa9a732548b194702e2b937b0390": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ff6916e84f44ec49d359ba252cbff67",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18b495ccac2e44e4abdaaf099a3b76a2",
            "value": 466062
          }
        },
        "466b835b30c64763b12de3806a4a8cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15af3efaca7f462aa4aa9ce7e5c77178",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2f5eb807da904d629262cfcd8722dbd9",
            "value": "â€‡570/570â€‡[00:00&lt;00:00,â€‡36.6kB/s]"
          }
        },
        "468b3ec7c678471f99567ba40b66ab57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65745083fa61487a91b5581ca092f232",
              "IPY_MODEL_4282aa9a732548b194702e2b937b0390",
              "IPY_MODEL_bd992956e47c41c68ccfd41b8fec0380"
            ],
            "layout": "IPY_MODEL_8d42d82130ff464480020a95a7d8a926"
          }
        },
        "4918f5f6401542ef958a0e2b8c5efd56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "498544775cac4691a8fae89d297c81d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49c83f426436433a8c39364fc71966b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff189e1e253d453b945224c54bd35846",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_671682fc1c7243a3b97352a52308a5c0",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "4ad932ec8bde4de385ff9bad774ca647": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53129bf630444613a826499f569878c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_255de73d638c4a569989b106e15909b0",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b9f195298e44e69ad99cb5d8654c1d3",
            "value": 48
          }
        },
        "532a1655acb54108bf974f67ebed4e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2deafb7e31248e2a38abdec99227a4a",
            "max": 2161,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d2725d66a5b4e6d969f162d2db2a0d0",
            "value": 2161
          }
        },
        "5803d324b6bb4c318908d286c0f8a4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aac77d5813b445b5a1cc5d661eca790a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ec4a7b4860f04ce5b71b8e3c11a5769e",
            "value": "â€‡2161/2161â€‡[00:02&lt;00:00,â€‡876.29â€‡examples/s]"
          }
        },
        "5d2725d66a5b4e6d969f162d2db2a0d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d9054c5548c468697b4d4ef5653dee6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ff6916e84f44ec49d359ba252cbff67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6208c326624a4ffc9d7b3f530eafba26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65745083fa61487a91b5581ca092f232": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71a293384c114bb8b7d76874ecc9eea9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_386eebf905f74f3e9a9f1e6c0ef6688a",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "671682fc1c7243a3b97352a52308a5c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68647247bd8c4b499e67a75ec99c6b7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c61fe0fde114560b301b7048f6a7e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ec896c3d3b94004a19a48aec5db0afc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f6b5e7258e447f2aa9a8b8cfe56a721": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bab6e96ccb144d36befda2d1c70bad93",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6208c326624a4ffc9d7b3f530eafba26",
            "value": "Map:â€‡100%"
          }
        },
        "6f88e745264042f98bf2d6a17d453b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "719cf28fc98c475d92591803e4e73f11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71a293384c114bb8b7d76874ecc9eea9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72b8cb1f96a94b5a9d35a6c87e70b4ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68647247bd8c4b499e67a75ec99c6b7a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6f88e745264042f98bf2d6a17d453b28",
            "value": "â€‡978/978â€‡[00:00&lt;00:00,â€‡1344.31â€‡examples/s]"
          }
        },
        "731e6ad98f8142f9b56043ae75c69900": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad2f1079caba468c8d8a6cceb14be6c5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_83563749f6fd45a88d9ad1b21a3e3dc6",
            "value": "â€‡2931/2931â€‡[00:02&lt;00:00,â€‡1320.47â€‡examples/s]"
          }
        },
        "7bb3d0c1bce44fae80f006f5709b7b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c388cb9342b4fbdaa35eca93d34e348",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_881705e1273e44e881f11d64804b9185",
            "value": 231508
          }
        },
        "7c0e4dcd2820473f8c06769d534e9a78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "834c4ec09c8b4c1e9795c892a52866b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83563749f6fd45a88d9ad1b21a3e3dc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83630888910b456bafd9a67ac32fbcb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f278e7bbbd954919bd1da4efcf0866b7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9ba8e7f9fb0c437d827d41cd1ea21951",
            "value": "â€‡232k/232kâ€‡[00:00&lt;00:00,â€‡3.15MB/s]"
          }
        },
        "881705e1273e44e881f11d64804b9185": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "897858d0953140dea5ae718956869d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49c83f426436433a8c39364fc71966b8",
              "IPY_MODEL_97637c83ed7e4b5a8a66d468b0dca527",
              "IPY_MODEL_41102555060d4569a786cedcc785e9f6"
            ],
            "layout": "IPY_MODEL_21d010d256c849f1936978013596bee1"
          }
        },
        "8d42d82130ff464480020a95a7d8a926": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97637c83ed7e4b5a8a66d468b0dca527": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daacc56bef12466a91f8e8b63b8b9409",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_834c4ec09c8b4c1e9795c892a52866b1",
            "value": 440449768
          }
        },
        "9a614b73c5f94d1a872eb44fd916133e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a70ee62f1ab4c40b2ae4b2767371833": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ba8e7f9fb0c437d827d41cd1ea21951": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e2f19394dd24077a52a05b07abb7c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ff28c2df88b43ce89a8b04cd25bf375": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a70ee62f1ab4c40b2ae4b2767371833",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a8bbaa6ec84346f8a1648fa3d2571a69",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "a7b76a19f26b4a9fa38746122f70ad74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8bbaa6ec84346f8a1648fa3d2571a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aac77d5813b445b5a1cc5d661eca790a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acc1cf89f3ee4819b47b4c150409ce72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d9054c5548c468697b4d4ef5653dee6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a7b76a19f26b4a9fa38746122f70ad74",
            "value": "â€‡48.0/48.0â€‡[00:00&lt;00:00,â€‡2.24kB/s]"
          }
        },
        "ad2f1079caba468c8d8a6cceb14be6c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bab6e96ccb144d36befda2d1c70bad93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd992956e47c41c68ccfd41b8fec0380": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2c41c6f47f143578b9e269cec67f676",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9a614b73c5f94d1a872eb44fd916133e",
            "value": "â€‡466k/466kâ€‡[00:00&lt;00:00,â€‡2.38MB/s]"
          }
        },
        "ccd0a8a3c43a437dac8bee685d89561c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d234508479794483876701c041f7a195": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a2fef74bd624b7c88aea6b56988ad4a",
              "IPY_MODEL_2f3f9b4a39294e18b8b4d0d7cbc626a5",
              "IPY_MODEL_72b8cb1f96a94b5a9d35a6c87e70b4ad"
            ],
            "layout": "IPY_MODEL_1d9d1d33bef2416380048c954f8495fe"
          }
        },
        "d2ad375f55ee481c84ecaabed781ff8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ff28c2df88b43ce89a8b04cd25bf375",
              "IPY_MODEL_53129bf630444613a826499f569878c7",
              "IPY_MODEL_acc1cf89f3ee4819b47b4c150409ce72"
            ],
            "layout": "IPY_MODEL_4918f5f6401542ef958a0e2b8c5efd56"
          }
        },
        "d2c41c6f47f143578b9e269cec67f676": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2fd9d3cf96c450bb4c4ce2e7316a8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da1709a7d2c74b838c1316352b6d69e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ad932ec8bde4de385ff9bad774ca647",
            "max": 2931,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd63392d24a641a495c8f17d31e90c4f",
            "value": 2931
          }
        },
        "daacc56bef12466a91f8e8b63b8b9409": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc9a2799168044cab69ef1decb9ce884": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8844db6c9f24128885a0dfdb2bf19f4",
              "IPY_MODEL_fc2140684a614e33a90853939b5a1daf",
              "IPY_MODEL_466b835b30c64763b12de3806a4a8cdc"
            ],
            "layout": "IPY_MODEL_f34edfcc3b044be1ba150b81090cdc8a"
          }
        },
        "dcabbfd7d22b4db884b11ba35f4781c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f6b5e7258e447f2aa9a8b8cfe56a721",
              "IPY_MODEL_da1709a7d2c74b838c1316352b6d69e8",
              "IPY_MODEL_731e6ad98f8142f9b56043ae75c69900"
            ],
            "layout": "IPY_MODEL_ccd0a8a3c43a437dac8bee685d89561c"
          }
        },
        "e06ef2ad74724bfab3b32b327e743838": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b2a85015b574d049d006756cd0b9d87",
              "IPY_MODEL_532a1655acb54108bf974f67ebed4e56",
              "IPY_MODEL_5803d324b6bb4c318908d286c0f8a4b5"
            ],
            "layout": "IPY_MODEL_6ec896c3d3b94004a19a48aec5db0afc"
          }
        },
        "e5ccca2a3fc94980b19b985e7e6cc8fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8844db6c9f24128885a0dfdb2bf19f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0af56e2ea96a4aa28816954ed32f914c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f4e39571c73d4f0ebf4b84de11b049fc",
            "value": "config.json:â€‡100%"
          }
        },
        "ec4a7b4860f04ce5b71b8e3c11a5769e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef64d246d81e4e91814932db4eba15fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f278e7bbbd954919bd1da4efcf0866b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2deafb7e31248e2a38abdec99227a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f34edfcc3b044be1ba150b81090cdc8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f392df123c9a42f2bf3eb6f9c5cb0b72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4e39571c73d4f0ebf4b84de11b049fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc2140684a614e33a90853939b5a1daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04e0877932a14b1882294d76add72f5e",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b63d9f2298a4e9da551bacaee024fc5",
            "value": 570
          }
        },
        "fd63392d24a641a495c8f17d31e90c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff189e1e253d453b945224c54bd35846": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
